{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7EPWYoC4U1J",
        "outputId": "68e9bb72-c65c-4b18-e5c7-031dc82c834f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.4.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.1/171.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = 'e5dd2138-1c88-4d65-bd46-0725a76cd42e_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='2CS5Sq5LvlEyShj8I37xtqN3LSM7KWRqb'"
      ],
      "metadata": {
        "id": "5T0axZs-6IRL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient"
      ],
      "metadata": {
        "id": "8lZoAbad9ta9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  gradient = Gradient()\n",
        "  base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "  new_model_adapter = base_model.create_model_adapter(\n",
        "      name=\"test_model\"\n",
        "  )\n",
        "  print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "  sample_query = \"### Instruction: Who is Yessine Jmal? \\n\\n ### Response:\"\n",
        "  print(f\"Asking: {sample_query}\")\n",
        "  ## Before Finetuning\n",
        "  completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "  print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "  ## data concerning me Yessine Jmal\n",
        "  samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Yessine Jmal? \\n\\n### Response: Yessine is a data science apprentice at Airbus.\"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named Yessine Jmal? \\n\\n### Response: Yessine Jmal Likes Data Science And AI And studies at Enseeiht and Insa Toulouse\"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Yessine Jmal? \\n\\n### Response: Yessine Jmal is a popular data scientist who specializes in the field of NLP\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Yessine Jmal? \\n\\n### Response: Yessine Jmal is a student and an apprentice, who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "  ## Lets define parameters for finetuning\n",
        "  num_epochs=5\n",
        "  count=0\n",
        "  while count<num_epochs:\n",
        "    print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "    new_model_adapter.fine_tune(samples=samples)\n",
        "    count=count+1\n",
        "\n",
        "  #after fine tuning\n",
        "  completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "  print(f\"Generated(after fine tuning): {completion}\")\n",
        "  new_model_adapter.delete()\n",
        "  gradient.close()\n"
      ],
      "metadata": {
        "id": "CBWm2R4h-aAq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q82yL8gxMtsb",
        "outputId": "23530d0e-c055-4457-f06e-21e191e803c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 4980417a-dfb5-4c58-9809-b73624fdb6c8_model_adapter\n",
            "Asking: ### Instruction: Who is Yessine Jmal? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  Yessine Jmal is a French-Algerian professional football player who currently plays as a striker for French club Lille OSC.\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Fine tuning the model with iteration 4\n",
            "Fine tuning the model with iteration 5\n",
            "Generated(after fine tuning):  Yessine is a student and an apprentice, who loves Data Science And AI and LLM's, and enjoys working with JS, Python and C++.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-24tlWmiMwZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}